{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1SnGDZklHz-afmlZ4Zts73Cga9Yx6d7GR",
      "authorship_tag": "ABX9TyNBW5lQNpCx3EJ5zQ8ESE0d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subhradipXD/Sentiment-Analysis/blob/main/MRSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **A Sentimental Analysis Case Study**"
      ],
      "metadata": {
        "id": "4u55iPeetU1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fetching Data**"
      ],
      "metadata": {
        "id": "FaD8opG64yYQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jwSCGGNy8axE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/DataSet/IMDB Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(20)"
      ],
      "metadata": {
        "id": "X0DxldzJtCQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'][0]"
      ],
      "metadata": {
        "id": "myttnGje1M6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Text Cleaning**"
      ],
      "metadata": {
        "id": "DUUlQQRZ5Gtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'].replace({'positive':1, 'negative':0},inplace = True)"
      ],
      "metadata": {
        "id": "kqQ60VED4ZKH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "5YJvaFB16Dje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "clean = re.compile('<.*?>')\n",
        "re.sub(clean, '' ,df.iloc[2].review)"
      ],
      "metadata": {
        "id": "bUqVeQ5Z6Jdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove html tags\n",
        "\n",
        "def clean_text(text):\n",
        "  clean = re.compile('<.*?>')\n",
        "  return re.sub(clean, '' ,text)"
      ],
      "metadata": {
        "id": "s7ivT_2Q6yT5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(clean_text)"
      ],
      "metadata": {
        "id": "rTl4z7uy7PJf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert into lower case\n",
        "\n",
        "def convert_lower_text(text):\n",
        "  return text.lower()"
      ],
      "metadata": {
        "id": "zJwSwDGX7gE3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(convert_lower_text)"
      ],
      "metadata": {
        "id": "LIgSAIzZ7y4Q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'][0]"
      ],
      "metadata": {
        "id": "Qy430unG7ygT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove special character\n",
        "\n",
        "def remove_special_char(text):\n",
        "  x = ''\n",
        "  for i in text:\n",
        "    if i.isalnum():\n",
        "      x=x+i;\n",
        "    else:\n",
        "      x=x+' '\n",
        "  return x"
      ],
      "metadata": {
        "id": "3nI0jZYb8cv-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(remove_special_char)"
      ],
      "metadata": {
        "id": "XER-2VI586Pv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "ZmMFQSsK9dR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "ME5NN_h_9mPX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "  x=[]\n",
        "  for i in text.split():\n",
        "    if i not in stopwords.words('english'):\n",
        "      x.append(i)\n",
        "\n",
        "  y = x[:]\n",
        "  x.clear()\n",
        "  return y"
      ],
      "metadata": {
        "id": "R29625Bc-BSx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('english')"
      ],
      "metadata": {
        "id": "XyhWadKdlhe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "VbL3rUur_MM6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review']"
      ],
      "metadata": {
        "id": "BGL_1Cp5Earu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Steamming\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()"
      ],
      "metadata": {
        "id": "oGRgCVqsLoSd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = []\n",
        "def stem_words(text):\n",
        "  for i in text:\n",
        "    y.append(ps.stem(i))\n",
        "\n",
        "  z=y[:]\n",
        "  y.clear()\n",
        "  return z"
      ],
      "metadata": {
        "id": "fpM0tjWyMHPd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(stem_words)"
      ],
      "metadata": {
        "id": "gmwyguTsMq6H"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def join_back(text):\n",
        "  return \" \".join(text)"
      ],
      "metadata": {
        "id": "ByVsO4AENG88"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(join_back)"
      ],
      "metadata": {
        "id": "xDLVpodKNZj_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review']"
      ],
      "metadata": {
        "id": "Pq7E6CBBNe4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tf-Idf Vectorizer**"
      ],
      "metadata": {
        "id": "-amcnrU5Hh4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF-IDF consists of two main components:** Term Frequency (TF) and Inverse Document Frequency (IDF), which are combined to assign a weight to each term in a document. Let's break down how TF-IDF works:\n",
        "\n",
        "**1. Term Frequency (TF):**\n",
        "\n",
        "Term Frequency measures how often a term (word) appears in a specific document.\n",
        "It is calculated for each term in a document using the following formula:\n",
        "\n",
        "# TF(t, d) = (Number of times term t appears in document d) / (Total number of terms in document d)\n",
        "\n",
        "\n",
        "The result is a value between 0 and 1, where 1 represents a high frequency of the term in the document.\n",
        "\n",
        "**2. Inverse Document Frequency (IDF):**\n",
        "\n",
        "Inverse Document Frequency measures the importance of a term across the entire corpus.\n",
        "It is calculated for each term in the corpus using the following formula:\n",
        "\n",
        "# IDF(t) = log_e(Total number of documents in the corpus / Number of documents containing term t)\n",
        "\n",
        "The IDF value is higher for terms that appear in fewer documents across the corpus, indicating their importance.\n",
        "\n",
        "**3. TF-IDF Score:**\n",
        "\n",
        "The TF-IDF score for a term in a document is obtained by multiplying its TF and IDF values:\n",
        "\n",
        "#TF-IDF(t, d) = TF(t, d) * IDF(t)\n",
        "\n",
        "The TF-IDF score reflects the importance of a term within a specific document while considering its rarity across the entire corpus. Here are some key points to understand about TF-IDF:\n",
        "\n",
        "**High TF-IDF Score**: A high TF-IDF score suggests that the term is both frequent in the document and unique to that document. Such terms are considered important for that specific document.\n",
        "\n",
        "**Low TF-IDF Score:** A low TF-IDF score indicates that the term is either common in the entire corpus or not prevalent in the document. These terms are considered less important for distinguishing the document's content.\n",
        "\n",
        "**Normalization:** To prevent bias towards longer documents, it's common to normalize TF by dividing it by the total number of terms in the document. This is called TF normalization.\n",
        "\n",
        "**Logarithmic Scaling:** The IDF is often calculated with a logarithmic scaling factor to reduce the impact of extremely rare terms.\n",
        "\n",
        "**Vector Representation:** After calculating TF-IDF scores for all terms in all documents, you can represent each document as a TF-IDF vector, where each dimension corresponds to a term, and the value in each dimension is the TF-IDF score for that term."
      ],
      "metadata": {
        "id": "bi2oEwpe-h0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tf-Idf vectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "x = vectorizer.fit_transform(df['review'])\n",
        "y =  df['sentiment']"
      ],
      "metadata": {
        "id": "Nz5ciVivNkxe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
      ],
      "metadata": {
        "id": "S46m2PN0yMJD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators=100,)\n",
        "classifier.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "phlEVtmj5uMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making predictions\n",
        "y_pred = classifier.predict(x_test)\n",
        "#model accuracy\n",
        "print(\"Model Accuracy : {}%\".format((y_pred == y_test).mean()))\n",
        "#confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "id": "LWm8RpX76k_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "print(confusion_matrix(y_test, y_pred, labels=[1,0]))"
      ],
      "metadata": {
        "id": "nMtPioM97FUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute confusion matrix\n",
        "import numpy as np\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure(figsize=(13,5))\n",
        "plot_confusion_matrix(cnf_matrix, classes=['positive=1','negative=0'],normalize= False,  title='Confusion matrix')"
      ],
      "metadata": {
        "id": "m2h2fTN37bMv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}